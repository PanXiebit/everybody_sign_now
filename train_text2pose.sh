python -m train_text2pose \
    --gpus 1 \
    --batchSize 32 \
    --data_path "Data/how2sign" \
    --text_path "data/text2gloss/" \
    --vocab_file "data/text2gloss/how2sign_vocab.txt" \
    --pose_vqvae "logs/SeqLen_{16}_TemDs_{1}_AttenType_{spatial-temporal-joint}_DecoderType_{divided-unshare}_ncodes_1024_mcodebooks/lightning_logs/version_1/checkpoints/epoch=12-step=38973.ckpt" \
    --hparams_file "logs/SeqLen_{16}_TemDs_{1}_AttenType_{spatial-temporal-joint}_DecoderType_{divided-unshare}_ncodes_1024_mcodebooks/lightning_logs/version_1/hparams.yaml" \
    --resume_ckpt "" \
    --default_root_dir "text2pose_logs/vec_reg" \
    --max_steps 300000 \
    --max_frames_num 400 \
    --gpu_ids "0,1" \